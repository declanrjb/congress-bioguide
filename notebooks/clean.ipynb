{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_name(data):\n",
    "    return data['givenName'] + ' ' + data['familyName']\n",
    "\n",
    "def extract_bio(data):\n",
    "    return data['profileText']\n",
    "\n",
    "def get_congresses(data):\n",
    "    jobs = data['jobPositions']\n",
    "    for job in jobs:\n",
    "        try:\n",
    "            yield job['congressAffiliation']['congress']['congressNumber']\n",
    "        except:\n",
    "            print('bad field')\n",
    "\n",
    "def load_bio(file):\n",
    "    with open(file,'r') as in_file:\n",
    "        data = json.load(in_file)\n",
    "        data = {k:data[k] for k in [x for x in ['usCongressBioId','givenName','middleName','familyName','birthDate','birthCirca','deathDate','deathCirca','image','profileText'] if x in data.keys()]}\n",
    "        data = streamline(data)\n",
    "        if 'image' in data:\n",
    "            if 'contentUrl' in data['image']:\n",
    "                data['image'] = data['image']['contentUrl']\n",
    "            else:\n",
    "                data['image'] = None\n",
    "        return pd.DataFrame({k:[data[k]] for k in data})\n",
    "\n",
    "def df_to_md(df,out_name):\n",
    "    with open(out_name,'w') as out_file:\n",
    "        for i in range(0,len(df['name'])):\n",
    "            out_file.write(f\"# {df['name'][i]}\\n\")\n",
    "            out_file.write(\" \\n\")\n",
    "            bio_lines = pd.Series(df['bio'][i].split(';')).apply(lambda x: x.strip())\n",
    "            for line in bio_lines:\n",
    "                if 'College' in line or 'University' in line:\n",
    "                    out_file.write(f\"- **{line}**\\n\")\n",
    "                else:\n",
    "                    out_file.write(f\"- {line}\\n\")\n",
    "            out_file.write(\" \\n\")\n",
    "\n",
    "def streamline(data):\n",
    "    for k in data:\n",
    "        if type(data[k]) == list:\n",
    "            if len(data[k]) > 0:\n",
    "                data[k] = data[k][0]\n",
    "            else:\n",
    "                data[k] = None\n",
    "    return data\n",
    "\n",
    "def clean_research_record(r_record):\n",
    "    if 'parentRecordLocation' in r_record['recordLocation']:\n",
    "        r_record['recordLocationName'] = r_record['recordLocation']['name'] + ', ' + r_record['recordLocation']['parentRecordLocation']['name']\n",
    "    else:\n",
    "        r_record['recordLocationName'] = r_record['recordLocation']['name']\n",
    "    r_record['recordLocationAddress'] = flatten_dict(r_record['recordLocation']['location'])\n",
    "    r_record = {k:r_record[k] for k in [x for x in ['name','recordType','description','recordLocationName','recordLocationAddress'] if x in r_record.keys()]}\n",
    "    r_record = streamline(r_record)\n",
    "    r_record = {k:[r_record[k]] for k in r_record}\n",
    "    return pd.DataFrame(r_record)\n",
    "\n",
    "def load_research_records(file):\n",
    "    with open(file,'r') as in_file:\n",
    "        data = json.load(in_file)\n",
    "    if len(data['researchRecord']) > 0:\n",
    "        temp = pd.concat([clean_research_record(record) for record in data['researchRecord']])\n",
    "        temp['usCongressBioId'] = data['usCongressBioId']\n",
    "        return temp\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def flatten_dict(dict):\n",
    "    return ', '.join(dict.values())\n",
    "\n",
    "def clean_job(job):\n",
    "    return pd.DataFrame({\n",
    "        'name':job['job']['name'] if 'name' in job['job'] else None,\n",
    "        'type':job['job']['jobType'] if 'jobType' in job['job'] else None,\n",
    "        'startDate':job['startDate'] if 'startDate' in job else None,\n",
    "        'startCirca':job['startCirca'] if 'startCirca' in job else None,\n",
    "        'congress':job['congressAffiliation']['congress']['congressNumber'] if 'congress' in job['congressAffiliation'] else None,\n",
    "        'congressType':job['congressAffiliation']['congress']['congressType'] if 'congress' in job['congressAffiliation'] else None,\n",
    "        'party':', '.join([party['party']['name'] for party in job['congressAffiliation']['partyAffiliation']]) if 'partyAffiliation' in job['congressAffiliation'] else None,\n",
    "        'caucus':', '.join([caucus['party']['name'] for caucus in job['congressAffiliation']['caucusAffiliation']]) if 'caucusAffiliation' in job['congressAffiliation'] else None,\n",
    "        'representing':job['congressAffiliation']['represents']['regionCode'] if 'represents' in job['congressAffiliation'] else None\n",
    "    },\n",
    "    index=[0])\n",
    "\n",
    "def load_jobs(file):\n",
    "    with open(file,'r') as in_file:\n",
    "        data = json.load(in_file)\n",
    "    job_sets = [clean_job(job) for job in data['jobPositions']]\n",
    "    if len(job_sets) > 0:\n",
    "        temp = pd.concat(job_sets)\n",
    "        temp['usCongressBioId'] = data['usCongressBioId']\n",
    "    else:\n",
    "        temp = None\n",
    "    return temp\n",
    "\n",
    "def clean_congress(job):\n",
    "    if 'congressAffiliation' in job and 'congress' in job['congressAffiliation']:\n",
    "        return pd.DataFrame(job['congressAffiliation']['congress'],index=[0])\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def load_congresses(file):\n",
    "    with open(file,'r') as in_file:\n",
    "        data = json.load(in_file)\n",
    "    congresses = [clean_congress(job) for job in data['jobPositions']]\n",
    "    if len(congresses) > 0:\n",
    "        temp = pd.concat(congresses)\n",
    "        temp['usCongressBioId'] = data['usCongressBioId']\n",
    "    else:\n",
    "        temp = None\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['../data/raw/' + file for file in os.listdir('../data/raw')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = pd.concat([load_bio(file) for file in files])\n",
    "directory = directory.reset_index(drop=True).fillna('')\n",
    "directory = directory.drop('image',axis=1)\n",
    "directory['fullName'] = directory['givenName'] + ' ' + directory['familyName']\n",
    "directory = directory[['usCongressBioId','fullName','givenName','middleName','familyName','birthDate','birthCirca','deathDate','deathCirca','profileText']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory.to_csv('../data/clean/directory.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "research_materials = pd.concat([load_research_records(file) for file in files])\n",
    "research_materials = research_materials.reset_index(drop=True).fillna('')\n",
    "research_materials = research_materials.merge(directory[['usCongressBioId','fullName']])\n",
    "research_materials = research_materials.rename(columns={\n",
    "    'fullName':'representativeName',\n",
    "    'name':'recordName',\n",
    "    'description':'recordDescription'\n",
    "})\n",
    "research_materials = research_materials[['usCongressBioId','representativeName','recordName','recordType','recordDescription','recordLocationName','recordLocationAddress']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "research_materials.to_csv('../data/clean/research-materials.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "congress_jobs = pd.concat([load_jobs(file) for file in files])\n",
    "congress_jobs = congress_jobs.reset_index(drop=True).fillna('')\n",
    "congress_jobs = congress_jobs.merge(directory[['usCongressBioId','fullName']])\n",
    "congress_jobs['congressID'] = congress_jobs['congressType'] + '_' + congress_jobs['congress'].apply(lambda x: str(x))\n",
    "congress_jobs = congress_jobs.rename(columns={\n",
    "    'name':'jobName',\n",
    "    'type':'jobType',\n",
    "    'fullName':'representativeName',\n",
    "    'startDate':'jobStartDate',\n",
    "    'startCirca':'jobStartCirca',\n",
    "    'representing':'stateRepresented'\n",
    "})\n",
    "congress_jobs = congress_jobs[['usCongressBioId','representativeName','congressID','jobName','jobType','stateRepresented','party','caucus','jobStartDate','jobStartCirca']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "congress_jobs.to_csv('../data/clean/congressional-positions.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "congresses = pd.concat([load_congresses(file) for file in files])\n",
    "congresses = congresses.reset_index(drop=True).fillna('')\n",
    "congresses = congresses[['name','congressNumber','congressType','startDate','endDate']].drop_duplicates()\n",
    "congresses['congressID'] = congresses['congressType'] + '_' + congresses['congressNumber'].apply(lambda x: str(x))\n",
    "congresses = congresses.rename(columns={\n",
    "    'name':'congressName',\n",
    "    'startDate':'congressStartDate',\n",
    "    'endDate':'congressEndDate'\n",
    "})\n",
    "congresses = congresses.sort_values('congressStartDate')\n",
    "congresses = congresses[congresses['congressStartDate'] != '']\n",
    "congresses = congresses.reset_index(drop=True)\n",
    "congresses = congresses[['congressID','congressNumber','congressName','congressType','congressStartDate','congressEndDate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "congresses.to_csv('../data/clean/congressional-sessions.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
